{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7-LiwqUMGYL"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pef9OF0t3LgO"
   },
   "source": [
    "### Create and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-SP8NPsMNRL"
   },
   "outputs": [],
   "source": [
    "# create data\n",
    "\n",
    "nPerClust = 300\n",
    "blur = 1\n",
    "\n",
    "A = [1, 1]\n",
    "B = [5, 1]\n",
    "C = [4, 3]\n",
    "\n",
    "# generate data\n",
    "a = [A[0] + np.random.randn(nPerClust) * blur, A[1] + np.random.randn(nPerClust) * blur]\n",
    "b = [B[0] + np.random.randn(nPerClust) * blur, B[1] + np.random.randn(nPerClust) * blur]\n",
    "c = [C[0] + np.random.randn(nPerClust) * blur, C[1] + np.random.randn(nPerClust) * blur]\n",
    "\n",
    "# true labels\n",
    "labels_np = np.hstack(\n",
    "    (np.zeros((nPerClust)), np.ones((nPerClust)), 1 + np.ones((nPerClust)))\n",
    ")\n",
    "\n",
    "# concatanate into a matrix\n",
    "data_np = np.hstack((a, b, c)).T\n",
    "\n",
    "# convert to a pytorch tensor\n",
    "data = torch.tensor(data_np).float()\n",
    "labels = torch.tensor(labels_np).long()  # note: \"long\" format for CCE\n",
    "\n",
    "# show the data\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "# draw distance to origin\n",
    "color = \"bkr\"\n",
    "for i in range(len(data)):\n",
    "    plt.plot([0, data[i, 0]], [0, data[i, 1]], color=color[labels[i]], alpha=0.2)\n",
    "\n",
    "plt.plot(\n",
    "    data[np.where(labels == 0)[0], 0],\n",
    "    data[np.where(labels == 0)[0], 1],\n",
    "    \"bs\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.plot(\n",
    "    data[np.where(labels == 1)[0], 0],\n",
    "    data[np.where(labels == 1)[0], 1],\n",
    "    \"ko\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.plot(\n",
    "    data[np.where(labels == 2)[0], 0],\n",
    "    data[np.where(labels == 2)[0], 1],\n",
    "    \"r^\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "plt.grid(color=[0.9, 0.9, 0.9])\n",
    "plt.title(\"The qwerties!\")\n",
    "plt.xlabel(\"qwerty dimension 1\")\n",
    "plt.ylabel(\"qwerty dimension 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycOTL-y10Uny"
   },
   "outputs": [],
   "source": [
    "# compute Euclidean distance to the origin\n",
    "dist2orig = torch.sqrt( data[:,0]**2 + data[:,1]**2 )\n",
    "\n",
    "plt.plot(labels+torch.randn(900)/10,dist2orig,'o')\n",
    "plt.xticks([0,1,2],labels=['blue','black','red'])\n",
    "plt.ylabel('Euclidean distance (a.u.)')\n",
    "plt.title('Distance to origin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "naNGUsQB3Js3"
   },
   "outputs": [],
   "source": [
    "# And add that to the data matrix\n",
    "dataAug = torch.cat((data,dist2orig.view(len(data),1)),axis=1)\n",
    "\n",
    "# check data sizes\n",
    "print(data.shape)\n",
    "print(dataAug.shape)\n",
    "print(' ')\n",
    "\n",
    "# look at some of the data\n",
    "print(dataAug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05kSm4Jkjvd_"
   },
   "outputs": [],
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataAug, labels, test_size=.1)\n",
    "\n",
    "# then convert them into PyTorch Datasets (note: already converted to tensors)\n",
    "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "batchsize    = 16\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wna1hFtQI9uk"
   },
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0YpD6f-j8dG"
   },
   "outputs": [],
   "source": [
    "class qwertyNet(nn.Module):\n",
    "    def __init__(self, useExtraFeature=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # input layer\n",
    "        if useExtraFeature:\n",
    "            self.input = nn.Linear(3, 8)\n",
    "        else:\n",
    "            self.input = nn.Linear(2, 8)\n",
    "\n",
    "        self.fc1 = nn.Linear(8, 8)\n",
    "        self.output = nn.Linear(8, 3)\n",
    "        self.useExtraFeature = useExtraFeature\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # by request, only use XY features\n",
    "        if not self.useExtraFeature:\n",
    "            x = x[:, :2]\n",
    "\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "def create_model(useExtraFeature=False):\n",
    "\n",
    "    net = qwertyNet(useExtraFeature)\n",
    "    lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "    return net, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8d-kIod6N76"
   },
   "outputs": [],
   "source": [
    "# test the model\n",
    "print('Using augmented feature:')\n",
    "net = create_model(True)[0]\n",
    "net(next(iter(train_loader))[0]);\n",
    "\n",
    "print('\\nNot using augmented feature:')\n",
    "net = create_model(False)[0]\n",
    "net(next(iter(train_loader))[0]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Q0nmoUPmu-5"
   },
   "outputs": [],
   "source": [
    "def function2trainTheModel(useExtraFeature=False):\n",
    "\n",
    "    numepochs = 200\n",
    "    net, lossfun, optimizer = create_model(useExtraFeature)\n",
    "    losses = torch.zeros(numepochs)\n",
    "    trainAcc = []\n",
    "    testAcc = []\n",
    "\n",
    "    for epochi in range(numepochs):\n",
    "        batchAcc = []\n",
    "        batchLoss = []\n",
    "        for X, y in train_loader:\n",
    "\n",
    "            # forward pass and loss\n",
    "            yHat = net(X)\n",
    "            loss = lossfun(yHat, y)\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss from this batch\n",
    "            batchLoss.append(loss.item())\n",
    "\n",
    "            # compute accuracy\n",
    "            batchAcc.append(100 * (torch.argmax(yHat, axis=1) == y).float().mean())\n",
    "\n",
    "        trainAcc.append(np.mean(batchAcc))\n",
    "        losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "        # test accuracy\n",
    "        X, y = next(iter(test_loader))  \n",
    "        with torch.no_grad():  \n",
    "            yHat = net(X)\n",
    "\n",
    "        # compare the following really long line of code to the training accuracy lines\n",
    "        testAcc.append(100 * torch.mean((torch.argmax(yHat, axis=1) == y).float()))\n",
    "\n",
    "    return trainAcc, testAcc, losses, net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHgeg-0eJBls"
   },
   "source": [
    "### run experiment and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmX6K49WMNuy"
   },
   "outputs": [],
   "source": [
    "#\n",
    "def run_experiment():\n",
    "\n",
    "    # compute accuracy over entire dataset (train+test)\n",
    "    yHat = net(dataAug)\n",
    "    predictions = torch.argmax(yHat, axis=1)\n",
    "    accuracy = (predictions == labels).float()\n",
    "\n",
    "    # and accuracy by group\n",
    "    accuracyByGroup = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        accuracyByGroup[i] = 100 * torch.mean(accuracy[labels == i])\n",
    "\n",
    "    # create the figure\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10, 6))\n",
    "\n",
    "    # plot the loss function\n",
    "    ax[0, 0].plot(losses.detach())\n",
    "    ax[0, 0].set_ylabel(\"Loss\")\n",
    "    ax[0, 0].set_xlabel(\"epoch\")\n",
    "    ax[0, 0].set_title(\"Losses\")\n",
    "\n",
    "    # plot the accuracy functions\n",
    "    ax[0, 1].plot(trainAcc, label=\"Train\")\n",
    "    ax[0, 1].plot(testAcc, label=\"Test\")\n",
    "    ax[0, 1].set_ylabel(\"Accuracy (%)\")\n",
    "    ax[0, 1].set_xlabel(\"Epoch\")\n",
    "    ax[0, 1].set_title(\"Accuracy\")\n",
    "    ax[0, 1].legend()\n",
    "\n",
    "    # plot overall accuracy by group\n",
    "    ax[1, 0].bar(range(3), accuracyByGroup)\n",
    "    ax[1, 0].set_ylim([np.min(accuracyByGroup) - 5, np.max(accuracyByGroup) + 5])\n",
    "    ax[1, 0].set_xticks([0, 1, 2])\n",
    "    ax[1, 0].set_xlabel(\"Group\")\n",
    "    ax[1, 0].set_ylabel(\"Accuracy (%)\")\n",
    "    ax[1, 0].set_title(\"Accuracy by group\")\n",
    "\n",
    "    # scatterplot of correct and incorrect labeled data\n",
    "    colorShapes = [\"bs\", \"ko\", \"g^\"]  # data markers\n",
    "    for i in range(3):\n",
    "        # plot all data points\n",
    "        ax[1, 1].plot(\n",
    "            dataAug[labels == i, 0],\n",
    "            dataAug[labels == i, 1],\n",
    "            colorShapes[i],\n",
    "            alpha=0.3,\n",
    "            label=f\"Group {i}\",\n",
    "        )\n",
    "\n",
    "        # cross-out the incorrect ones\n",
    "        idxErr = (accuracy == 0) & (labels == i)\n",
    "        ax[1, 1].plot(dataAug[idxErr, 0], dataAug[idxErr, 1], \"rx\")\n",
    "\n",
    "    ax[1, 1].set_title(\"All groups\")\n",
    "    ax[1, 1].set_xlabel(\"qwerty dimension 1\")\n",
    "    ax[1, 1].set_ylabel(\"qwerty dimension 2\")\n",
    "    ax[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWOrG6NEJFgk"
   },
   "source": [
    "# Test the model with and without the additional feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "of9E8ClxMNsD"
   },
   "outputs": [],
   "source": [
    "# run the model and visualize the results\n",
    "trainAcc,testAcc,losses,net = function2trainTheModel(False)\n",
    "print('Final accuracy: %.2f%%' %testAcc[-1].item())\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMCInlW6xKCw"
   },
   "outputs": [],
   "source": [
    "# run the model and visualize the results\n",
    "trainAcc,testAcc,losses,net = function2trainTheModel(True)\n",
    "print('Final accuracy: %.2f%%' %testAcc[-1].item())\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0OnhQt7XI35"
   },
   "source": [
    "### t-test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iw3XkEMb-bIy"
   },
   "outputs": [],
   "source": [
    "n=30\n",
    "\n",
    "finalacc2 = np.zeros(n)\n",
    "finalacc3 = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "  finalacc2[i] = np.mean(function2trainTheModel(False)[1][-10:])\n",
    "  finalacc3[i] = np.mean(function2trainTheModel(True)[1][-10:])\n",
    "  print(f\"Finished iteration {i+1}/{n}\")\n",
    "\n",
    "# run the t-test and print the results\n",
    "from scipy import stats\n",
    "t,p = stats.ttest_ind(finalacc3,finalacc2)\n",
    "print('\\n\\nt=%.2f, p=%.2f' %(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.plot(finalacc2,'bo-',label='2 features')\n",
    "plt.plot(finalacc3,'ro-',label='3 features')\n",
    "plt.xlabel('Simulation')\n",
    "plt.ylabel('Final accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5mKg4L1QRDxrTd6cuaPxi",
   "collapsed_sections": [],
   "name": "DUDL_data_featureAugmentation.ipynb",
   "provenance": [
    {
     "file_id": "1M7eY1x1xa6KsvY0Q6w5RxLXFHc0kbuJQ",
     "timestamp": 1618427721531
    },
    {
     "file_id": "1Yp9bgltmsXuxkNPmbKEC1kn7bkBQD5WD",
     "timestamp": 1617649131489
    },
    {
     "file_id": "10_geQnah5AvMsm8VDAQwNPhypOXradar",
     "timestamp": 1617634658608
    },
    {
     "file_id": "1FtQ99beHYcDFDywLdaPgFm-KjBeI8PvD",
     "timestamp": 1615877547147
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
